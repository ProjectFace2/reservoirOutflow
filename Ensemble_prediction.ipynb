{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBra3EclPGo6ajv5QQMkzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectFace2/reservoirOutflow/blob/master/Ensemble_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdRkvGgfdab2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5971cfa3-b9aa-4d88-cb09-1884c5c00049"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import concatenate\n",
        "from datetime import datetime\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from math import sqrt\n",
        "import fbprophet as fb\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re2FDmyBjLPo",
        "colab_type": "text"
      },
      "source": [
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uy3pwMtfkbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "In this method, we use all the lag days and lead days and construct a dataframe, where\n",
        "the lag and lead days are represented in a single row\n",
        "Using these features we can predict the class of the present day with the data from the previous days\n",
        "This holds good for all the rows in the dataframe\n",
        "'''\n",
        "\n",
        "#dataset preparation with lag\n",
        "def series_to_supervised(data, lag_days=1, lead_days=1, dropnan=True):\n",
        "    no_of_features = 1 if type(data) is list else data.shape[1]\n",
        "    print(no_of_features)\n",
        "    df = pd.DataFrame(data)\n",
        "    cols, names = list(), list()\n",
        "    # input sequence (t-n, ... t-1)\n",
        "    for i in range(lag_days, 0, -1):\n",
        "        cols.append(df.shift(i))\n",
        "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(no_of_features)]\n",
        "    # forecast sequence (t, t+1, ... t+n)\n",
        "    for i in range(0, lead_days):\n",
        "        cols.append(df.shift(-i))\n",
        "        if i == 0:\n",
        "            names += [('var%d(t)' % (j+1)) for j in range(no_of_features)]\n",
        "        else:\n",
        "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(no_of_features)]\n",
        "# put it all together\n",
        "    agg = pd.concat(cols, axis=1)\n",
        "    agg.columns = names\n",
        "    # drop rows with NaN values\n",
        "    if dropnan:\n",
        "        agg.dropna(inplace=True)\n",
        "    return agg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTqldl39wobh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LocallyWeightedRegression:\n",
        "    def __init__(self):\n",
        "        return\n",
        "        \n",
        "    def setup(self,X,y):\n",
        "        lag_val = int(X.shape[1]/4)\n",
        "        begin_year = ''\n",
        "        if(lag_val==9):\n",
        "            begin_year='2011-01-10'\n",
        "        else:\n",
        "            begin_year='2011-01-05'\n",
        "        self.train_x,self.train_y = self.init_train( lag_val, begin_year)\n",
        "\n",
        "    def fit(self, train_x, train_y):\n",
        "        self.setup(train_x,train_y)\n",
        "\n",
        "    def init_train( self, lag_val=4, begin_year='2011-01-05'):\n",
        "        df = pd.read_csv('/home/kishora/Documents/Datasets/allYearLabeledHarangi.csv',header=0,parse_dates=True,index_col=0)\n",
        "        x=df.drop([\"Present Storage(TMC)\",'Reservoir Level(TMC)','Outflow','Label'],axis = 1)\n",
        "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled = self.scaler.fit_transform(x.values)\n",
        "        reshaped=pd.DataFrame({'Inflow':scaled[:,0],'MADIKERI':scaled[:,1],'SOMWARPET':scaled[:,2],'VIRAJPET':scaled[:,3]})\n",
        "        idx = pd.date_range('2011-01-01', '2018-12-31') \n",
        "        reshaped['Dates']=idx\n",
        "        df=reshaped\n",
        "        df['month'] = pd.DatetimeIndex(df[\"Dates\"]).month\n",
        "        df['year'] = pd.DatetimeIndex(df[\"Dates\"]).year\n",
        "        mask = (df['month'] <= 12)\n",
        "        mask1 = (df['year'] >= 2011)&(df['year'] <= 2018)\n",
        "        df = df.loc[mask]\n",
        "        df = df.loc[mask1]\n",
        "        df.set_index('Dates',inplace = True)\n",
        "        df.drop(['month','year'],axis = 1,inplace = True)\n",
        "#         lag_val = 4\n",
        "        values = df.values\n",
        "        values = values.astype('float32')\n",
        "        reframed = series_to_supervised(values, lag_val, 1)#lag of 4 days\n",
        "        reframed.drop(reframed.columns[[-1,-2,-3]], axis=1, inplace=True)\n",
        "        idx = pd.date_range(begin_year, '2018-12-31') \n",
        "        reframed['Dates']=idx\n",
        "        reframed['month']=pd.DatetimeIndex(reframed['Dates']).month\n",
        "        reframed=reframed.sort_values(by=['month','Dates'])\n",
        "        reframed.drop(columns=['month','Dates'],inplace=True)\n",
        "        values = reframed.values\n",
        "        train_x = values[:,:-1]\n",
        "        Inflow = values[:,-1]\n",
        "        train_y = Inflow.reshape((train_x.shape[0],1))\n",
        "        return train_x,train_y\n",
        "   \n",
        "    #locally weighted regression\n",
        "\n",
        "    def lwr1(self,x0, inp, out, k):\n",
        "        m,n = np.shape(inp)\n",
        "        ypred = np.zeros(m)    \n",
        "        ypred = x0 * self.beta(x0, inp, out, k)\n",
        "        #print(\"The final prediction is :\",ypred)\n",
        "        return ypred\n",
        "    \n",
        "    def beta(self,point, inp, out, k):\n",
        "        wt = self.kernal(point, inp, k)\n",
        "        #print(\"The weight of betas is\",wt)\n",
        "        beta_val = (inp.T * (wt*inp)).I * inp.T * wt * out\n",
        "        #print(\"The weight is beta value is\",beta_val)\n",
        "        return beta_val\n",
        "    \n",
        "    def kernal(self,point, inp, k):\n",
        "        l,b = np.shape(inp)\n",
        "        weights = np.mat(np.eye((l)))\n",
        "        #print(weights)    \n",
        "        for i in range(l):\n",
        "            #print(point.shape,inp[i].shape)\n",
        "            diff = point - inp[i]\n",
        "            weights[i,i] = np.exp(np.dot(diff,diff.T) / (-2.0 * (k**2)))\n",
        "        return weights\n",
        "    \n",
        "    def call_Lwr(self, test_x,train_x,train_y,k=0):\n",
        "            ypred = []\n",
        "            train_X = train_x\n",
        "            train_y = train_y\n",
        "            for i in test_x:\n",
        "                ypred.append(self.lwr1(i, train_X, train_y, 7.15))\n",
        "            ypred = np.array(ypred).reshape(len(ypred),1)\n",
        "            inv_yhat = np.concatenate((ypred, test_x[:, -3:]), axis=1)\n",
        "            out=self.scaler.inverse_transform(inv_yhat) \n",
        "            out=out[:,0]\n",
        "            return out\n",
        "\n",
        "    def predict(self, test_x):\n",
        "        return self.call_Lwr(test_x,self.train_x,self.train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD7YKrhVpwM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(queryset,date):\n",
        "  '''based on query set ,and given date range predicts result for given date with multiple models and returns ensembled result \n",
        "    query set can be single row or multiple row set, in case of multiple set use dataframe range with set of prediction seeking dates \n",
        "  '''\n",
        "  # lstm prediction\n",
        "  n_hours = 9\n",
        "  n_features = 4\n",
        "  test_x=queryset.values\n",
        "  lstm_test_X = test_x.reshape((test_x.shape[0], n_hours, n_features))\n",
        "  with open('models/lstmInf_forecast_model_lag9.pckl', 'rb') as fin:\n",
        "    lstm_lag4_model = pickle.load(fin)\n",
        "  lstm_inv_yhat=lstm_lag4_model.predict(lstm_test_X)\n",
        "  test_X = lstm_test_X.reshape((lstm_test_X.shape[0], n_hours*n_features))\n",
        "  inv_yhatx = concatenate((lstm_inv_yhat, test_X[:, -3:]), axis=1)\n",
        "  inv_yhaty = scaler.inverse_transform(inv_yhatx)\n",
        "  lstm_res = inv_yhaty[:,0]\n",
        "\n",
        "  # fb prophet prediction\n",
        "  fb_test=queryset.copy()\n",
        "  varList=fb_test.columns.tolist()\n",
        "  varList.insert(0,'ds')\n",
        "  fb_test['ds']=date\n",
        "  fb_test_X = pd.DataFrame(fb_test[varList])\n",
        "  with open('models/fbInf_forecast_model_lag9.pckl', 'rb') as fin:\n",
        "    proph_lag4_model = pickle.load(fin)\n",
        "  proph_inv_yhat = proph_lag4_model.predict(fb_test_X).values\n",
        "  proph_res = proph_inv_yhat[:,-1]\n",
        "\n",
        "  # lwr prediction\n",
        "  lwr_test=queryset.values\n",
        "  # print(lwr_test.shape,queryset.values.shape)\n",
        "  with open('models/lwrInf_forecast_model_lag9.pckl', 'rb') as fin:\n",
        "    lwr_lag4_model = pickle.load(fin)\n",
        "  lwr_res = lwr_lag4_model.predict(lwr_test)\n",
        "\n",
        "  # ensembled prediction\n",
        "  inp=pd.DataFrame()\n",
        "  inp['lstm']=lstm_res\n",
        "  inp['proph']=proph_res\n",
        "  inp['lwr']=lwr_res\n",
        "  with open('models/ensemble_forecast_model_lag9.pckl', 'rb') as fin:\n",
        "    en_lag4_model = pickle.load(fin)\n",
        "  prediction = en_lag4_model.predict(inp[['lstm','proph','lwr']])\n",
        "  return prediction\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16s4VjxjeUHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Datasets/allYearHarangi.csv',index_col=0)\n",
        "df.drop([\"Present Storage(TMC)\",'Reservoir Level(TMC)','Outflow'],axis = 1,inplace = True)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(df.values)\n",
        "reshaped=pd.DataFrame({'Inflow':scaled[:,0],'MADIKERI':scaled[:,1],'SOMWARPET':scaled[:,2],'VIRAJPET':scaled[:,3]})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwn9KBVPlb-b",
        "colab_type": "code",
        "outputId": "b4fa8fc3-28bf-4e50-8798-9870ae3310a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x=reshaped.values\n",
        "qwtest=series_to_supervised(x,9,1)\n",
        "qwtest.drop(qwtest.columns[[-1,-2,-3]], axis=1, inplace=True)\n",
        "qwtest_x=qwtest.iloc[-1087:,:-1]\n",
        "qwtest_y=qwtest.values[-1087:,-1:]\n",
        "dates = pd.date_range('2016-01-10','2018-12-31')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxaXmkA8pltD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "9e4a190a-3668-4573-f392-24ccbe66763f"
      },
      "source": [
        "inp=predict(qwtest_x,dates)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning:\n",
            "\n",
            "Trying to unpickle estimator MinMaxScaler from version 0.21.3 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZssQsQNu1XjP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "40d241e6-82a1-4371-f533-553d21147989"
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 22.04370959]\n",
            " [119.86053917]\n",
            " [146.06190917]\n",
            " ...\n",
            " [222.14660425]\n",
            " [413.8946097 ]\n",
            " [303.71976928]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}